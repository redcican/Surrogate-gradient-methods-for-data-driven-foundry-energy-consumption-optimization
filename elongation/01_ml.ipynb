{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 20:24:13.760954: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 20:24:13.774017: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 20:24:13.892204: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 20:24:14.008296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740227054.104890  115952 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740227054.131468  115952 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 20:24:14.365024: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>I14</th>\n",
       "      <th>I15</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.652</td>\n",
       "      <td>24.739</td>\n",
       "      <td>21.857</td>\n",
       "      <td>45.095</td>\n",
       "      <td>36.583</td>\n",
       "      <td>27.420</td>\n",
       "      <td>41.849</td>\n",
       "      <td>29.251</td>\n",
       "      <td>24.4270</td>\n",
       "      <td>39.156</td>\n",
       "      <td>31.525</td>\n",
       "      <td>29.661</td>\n",
       "      <td>22.298</td>\n",
       "      <td>37.114</td>\n",
       "      <td>31.930</td>\n",
       "      <td>122.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.007</td>\n",
       "      <td>23.648</td>\n",
       "      <td>37.083</td>\n",
       "      <td>21.532</td>\n",
       "      <td>36.033</td>\n",
       "      <td>25.703</td>\n",
       "      <td>38.035</td>\n",
       "      <td>33.229</td>\n",
       "      <td>9.0067</td>\n",
       "      <td>22.466</td>\n",
       "      <td>44.577</td>\n",
       "      <td>13.691</td>\n",
       "      <td>26.670</td>\n",
       "      <td>33.056</td>\n",
       "      <td>30.683</td>\n",
       "      <td>107.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.297</td>\n",
       "      <td>33.818</td>\n",
       "      <td>21.227</td>\n",
       "      <td>48.211</td>\n",
       "      <td>35.864</td>\n",
       "      <td>39.852</td>\n",
       "      <td>33.195</td>\n",
       "      <td>51.299</td>\n",
       "      <td>36.9970</td>\n",
       "      <td>37.245</td>\n",
       "      <td>37.786</td>\n",
       "      <td>51.839</td>\n",
       "      <td>33.949</td>\n",
       "      <td>46.883</td>\n",
       "      <td>36.635</td>\n",
       "      <td>120.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.610</td>\n",
       "      <td>14.372</td>\n",
       "      <td>31.512</td>\n",
       "      <td>26.721</td>\n",
       "      <td>22.922</td>\n",
       "      <td>38.254</td>\n",
       "      <td>39.524</td>\n",
       "      <td>33.275</td>\n",
       "      <td>42.9710</td>\n",
       "      <td>20.904</td>\n",
       "      <td>40.671</td>\n",
       "      <td>22.071</td>\n",
       "      <td>17.671</td>\n",
       "      <td>25.432</td>\n",
       "      <td>19.461</td>\n",
       "      <td>109.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.274</td>\n",
       "      <td>19.442</td>\n",
       "      <td>19.182</td>\n",
       "      <td>48.360</td>\n",
       "      <td>46.518</td>\n",
       "      <td>32.365</td>\n",
       "      <td>27.234</td>\n",
       "      <td>16.937</td>\n",
       "      <td>26.1260</td>\n",
       "      <td>24.334</td>\n",
       "      <td>34.613</td>\n",
       "      <td>39.486</td>\n",
       "      <td>33.299</td>\n",
       "      <td>22.766</td>\n",
       "      <td>34.507</td>\n",
       "      <td>115.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       I1      I2      I3      I4      I5      I6      I7      I8       I9  \\\n",
       "0  41.652  24.739  21.857  45.095  36.583  27.420  41.849  29.251  24.4270   \n",
       "1  26.007  23.648  37.083  21.532  36.033  25.703  38.035  33.229   9.0067   \n",
       "2  26.297  33.818  21.227  48.211  35.864  39.852  33.195  51.299  36.9970   \n",
       "3  34.610  14.372  31.512  26.721  22.922  38.254  39.524  33.275  42.9710   \n",
       "4  37.274  19.442  19.182  48.360  46.518  32.365  27.234  16.937  26.1260   \n",
       "\n",
       "      I10     I11     I12     I13     I14     I15       D  \n",
       "0  39.156  31.525  29.661  22.298  37.114  31.930  122.46  \n",
       "1  22.466  44.577  13.691  26.670  33.056  30.683  107.44  \n",
       "2  37.245  37.786  51.839  33.949  46.883  36.635  120.03  \n",
       "3  20.904  40.671  22.071  17.671  25.432  19.461  109.05  \n",
       "4  24.334  34.613  39.486  33.299  22.766  34.507  115.82  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('elongation.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.94323513333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['D'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and target\n",
    "X = df.drop(columns=['D'])\n",
    "y = df['D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_ann(lr):\n",
    "    model = keras.Sequential([\n",
    "      layers.Dense(10, activation='relu'), \n",
    "      layers.Dense(20, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(lr))\n",
    "    return model\n",
    "\n",
    "def train_ann(X_train, y_train, epochs, lr):\n",
    "    ann_model = build_and_compile_ann(lr)\n",
    "    history = ann_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        verbose=0, epochs=epochs)\n",
    "    return ann_model, history\n",
    "\n",
    "def train_xgb(X_train, y_train):\n",
    "    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of ANN:  0.911049544644521\n",
      "R2 score of XGBoost:  0.9777288141871708\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "\n",
    "X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train = X_df_train.values\n",
    "y_train = y_df_train.values\n",
    "\n",
    "xgb_model = train_xgb(X_train, y_train)\n",
    "    \n",
    "ann_model, history = train_ann(X_train, y_train, epochs=3, lr=0.1)\n",
    "    \n",
    "y_pred_ann = ann_model.predict(X_df_test)\n",
    "y_pred_xgb = xgb_model.predict(X_df_test.values)\n",
    "r2_ann = r2_score(y_df_test, y_pred_ann.flatten())\n",
    "mse_ann = mean_squared_error(y_df_test, y_pred_ann.flatten())\n",
    "r2_xgb = r2_score(y_df_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_df_test, y_pred_xgb)\n",
    "print(f\"R2 score of ANN: \", r2_ann)\n",
    "print(f\"R2 score of XGBoost: \", r2_xgb)\n",
    "    #\n",
    "metadata_n = {'ANN_R2': r2_ann,'ANN_MSE':mse_ann, 'XGB_R2': r2_xgb,'XGB_MSE':mse_xgb}\n",
    "metadata.update(metadata_n)\n",
    "    #\n",
    "ann_model.save(f'models/ANN.h5')\n",
    "xgb_model.save_model(f'models/XGB.json')\n",
    "\n",
    "with open('models/metadata.json', 'w') as file:\n",
    "    json.dump(metadata, file)\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
